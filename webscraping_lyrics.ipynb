{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T14:56:43.826119Z",
     "start_time": "2020-01-08T14:56:43.798195Z"
    }
   },
   "outputs": [],
   "source": [
    "# inputs\n",
    "\n",
    "# urls = ['https://songteksten.net/artist/lyrics/1938/evanescence.html',\n",
    "#        'https://songteksten.net/artist/lyrics/1938/evanescence/page/2.html',\n",
    "#        'https://songteksten.net/artist/lyrics/1938/evanescence/page/3.html']\n",
    "\n",
    "# path_csv = \"./data/lyrics_evanescence.csv\"\n",
    "\n",
    "urls = ['https://songteksten.net/artist/lyrics/320/within-temptation.html',\n",
    "       'https://songteksten.net/artist/lyrics/320/within-temptation/page/2.html',\n",
    "       'https://songteksten.net/artist/lyrics/320/within-temptation/page/3.html']\n",
    "\n",
    "path_csv = \"./data/lyrics_within_temptation.csv\"\n",
    "\n",
    "\n",
    "# retrieve hyperlinks\n",
    "\n",
    "# importing packages\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def retrieve_hyperlinks(main_url):\n",
    "    \"\"\" Extract all hyperlinks in 'main_url' and return a list with these hyperlinks \"\"\"\n",
    "    \n",
    "    # Packages the request, send the request and catch the response: r\n",
    "\n",
    "    r = requests.get(main_url)\n",
    "\n",
    "    # Extracts the response as html: html_doc\n",
    "    html_doc = r.text\n",
    "\n",
    "    # Create a BeautifulSoup object from the HTML: soup\n",
    "    soup = BeautifulSoup(html_doc)\n",
    "    \n",
    "    # Find all 'a' tags (which define hyperlinks): a_tags\n",
    "\n",
    "    a_tags = soup.find_all('a')\n",
    "    \n",
    "    # Create a list with hyperlinks found\n",
    "\n",
    "    list_links = [link.get('href') for link in a_tags]\n",
    "    \n",
    "    # Remove none values if there is some\n",
    "    \n",
    "    list_links = list(filter(None, list_links)) \n",
    "    \n",
    "    return list_links\n",
    "\n",
    "# retrieving all hyperlinks\n",
    "\n",
    "list_links_lyrics_songteksten_net = []\n",
    "\n",
    "for url in urls:\n",
    "    list_links_lyrics_songteksten_net.extend(retrieve_hyperlinks(url))\n",
    "    \n",
    "# removing possible duplicates\n",
    "list_links_lyrics_songteksten_net = list(set(list_links_lyrics_songteksten_net))\n",
    "\n",
    "    \n",
    "# print('Number of links before filtering:', len(list_links_lyrics_songteksten_net))\n",
    "\n",
    "# filtering hyperlinks which contain lyrics - specific for songteksten.net\n",
    "\n",
    "# using url address to filter lyrics\n",
    "\n",
    "spliting = urls[0].split('/')\n",
    "filter_lyrics = spliting[2]+'/lyric/'+spliting[-2]\n",
    "\n",
    "list_links_lyrics_songteksten_net = [link for link in list_links_lyrics_songteksten_net if (filter_lyrics \n",
    "                                                                              in link) ]\n",
    "\n",
    "# print('Number of links after filtering:', len(list_links_lyrics_songteksten_net))\n",
    "\n",
    "# Extract lyrics from hyperlinks\n",
    "\n",
    "def extract_lyric_from_url(url_lyric):\n",
    "    \"\"\" Extract lyrics after prettify beautiful soup from www.songteksten.nl \"\"\"\n",
    "    \n",
    "    \n",
    "    # send a http request\n",
    "    r_lyric = requests.get(url_lyric)\n",
    "    \n",
    "    # obtain text with html containt of the url\n",
    "    html_doc_lyric = r_lyric.text\n",
    "    \n",
    "    # making html easier to read\n",
    "    soup_lyric = BeautifulSoup(html_doc_lyric)\n",
    "\n",
    "    \n",
    "    # prettifying it\n",
    "    soup_lyric_pretty = soup_lyric.prettify()\n",
    "    \n",
    "    # Isolating deal that contains the lyric\n",
    "    \n",
    "    text = soup_lyric_pretty.split('</h1>\\n')[1].split('<div class=\"buma-consent\" role=\"alert\">')[0]\n",
    "\n",
    "    # Cleaning text and building a list with it\n",
    "    list_lyrics = text.split('<br/>\\n')\n",
    "    list_lyrics = [item.replace('\\n','') for item in list_lyrics]\n",
    "    list_lyrics = [item.lstrip().rstrip() for item in list_lyrics]\n",
    "    \n",
    "    # removing empty elements from the list\n",
    "    \n",
    "    for item in list_lyrics:\n",
    "        if str(item) == '':\n",
    "            list_lyrics.remove(item)\n",
    "            \n",
    "    # this part was added after noticing that at least one lyric was not following the normal pattern\n",
    "    \n",
    "    if '<div' in list_lyrics[0]:\n",
    "        list_lyrics = list_lyrics[1:]\n",
    "        \n",
    "        \n",
    "    # Having the lyrics in string format\n",
    "    \n",
    "    lyrics = '. '.join(list_lyrics)\n",
    "            \n",
    "    \n",
    "    # returning both list and string\n",
    "    \n",
    "    return list_lyrics, lyrics\n",
    "\n",
    "list_lyrics = []\n",
    "list_title_lyrics = []\n",
    "\n",
    "# building lists with titles of lyrics and lyrics\n",
    "\n",
    "for url_lyric in list_links_lyrics_songteksten_net:\n",
    "    \n",
    "    list_title_lyrics.append(url_lyric.split('/')[-1].split('.')[-2])\n",
    "    list_lyrics.append(extract_lyric_from_url(url_lyric)[1])\n",
    "\n",
    "\n",
    "# Creating a dataframe with song titles and lyrics\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'song_title': list_title_lyrics,\n",
    "                  'lyrics': list_lyrics})\n",
    "\n",
    "# remove '-' from titles and lower case\n",
    "\n",
    "df['song_title'] = df['song_title'].apply(lambda x: x.replace('-',' ').lower())\n",
    "\n",
    "# saving dataframe to .csv\n",
    "\n",
    "df.to_csv(path_csv, index = False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
